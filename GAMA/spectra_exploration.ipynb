{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the __GAMA__ spectroscopic catalog\n",
    "notebook by _Alex Malz (GCCL@RUB)_, _Kara Ponder (UC Berkeley)_, (add your name here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sncosmo\n",
    "import urllib.request as ur\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get the spectra of galaxies matching conditions found [here](http://www.gama-survey.org/dr3/schema/table.php?id=31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('SpecObj.fits') as hdul:\n",
    "    hdul.info()\n",
    "#     print(hdul[1].header)\n",
    "    df = pd.DataFrame(np.array(hdul[1].data).byteswap().newbyteorder())\n",
    "    print(df.columns)\n",
    "    df.index = df['CATAID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy redshifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each galaxy in the GAMA catalog has a spectroscopically confirmed redshift.  \n",
    "We're going to match these redshifts to the snapshots of the particle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_SLICS = np.array([0.042, 0.080, 0.130, 0.221, 0.317, 0.418, 0.525, 0.640, 0.764, 0.897, \n",
    "           1.041, 1.199, 1.372, 1.562, 1.772, 2.007, 2.269, 2.565, 2.899])\n",
    "z_mids = (z_SLICS[1:] + z_SLICS[:-1]) / 2.\n",
    "z_bins = np.insert(z_mids, 0, min(df['Z']))\n",
    "z_bins = np.append(z_mids, max(df['Z']))\n",
    "plt.hist(df['Z'], bins=z_bins)\n",
    "plt.semilogy()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('number of galaxies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of redshift is skewed by the use of `z=10` as a placeholder for not having a secure redshift.  \n",
    "GAMA has a quality flag we can use to filter for redshifts that were considered of sufficient quality for science use, which they define as `NQ > 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moar_bins = np.arange(z_bins[0], z_bins[-1] + z_bins[1], z_bins[1])\n",
    "for i in range(5):\n",
    "    quality = df.loc[df['NQ'] == i+1, 'Z']\n",
    "    plt.hist(quality, alpha=0.5, label=str(i+1), bins=moar_bins)\n",
    "plt.legend(loc='upper right')\n",
    "plt.semilogy()\n",
    "plt.xlim(moar_bins[0], moar_bins[-1])\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('number of galaxies')\n",
    "plt.title('redshift distributions by quality flag \"NQ\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAMA observed galaxies in four disjoint regions of the sky.\n",
    "Since environment is about the immediate vicinity of each galaxy, we'll have to divide the galaxies by region, effectively building our redshift-environment-color distribution separately for each region before combining those findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(np.array([df['RA'], df['DEC']]).T, labels=['RA', 'DEC'], show_titles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select spectra by redshift and field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RA_bin_ends = [0., 80., 160., 200., 360.]\n",
    "subsamples, lens = [], []\n",
    "for i in range(len(RA_bin_ends)-1):\n",
    "    subsamples.append(df.loc[(df['RA'] >= RA_bin_ends[i]) & (df['RA'] < RA_bin_ends[i+1]) \n",
    "                             & (df['NQ'] > 2), ['RA', 'DEC', 'Z', 'NQ', 'URL', 'FILENAME']])\n",
    "    lens.append(len(subsamples[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = np.argmin(lens)\n",
    "chosen_ind = subsamples[subset].sample(1, random_state=42).index[0]\n",
    "# chosen_ind = subsamples[subset].sample(1).index[0]\n",
    "subsamples[subset].URL[chosen_ind].decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "just_url = subsamples[subset].URL[chosen_ind].decode('ascii')\n",
    "just_fn = subsamples[subset].FILENAME[chosen_ind].decode('ascii')[1:]\n",
    "os.makedirs(os.path.dirname(just_fn), exist_ok=True)\n",
    "spectrum = ur.urlretrieve(just_url, just_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with fits.open(just_fn) as hdul:\n",
    "    arr = np.array(hdul[0].data).byteswap().newbyteorder()\n",
    "    metadata = hdul[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download more spectra to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to grab the spectra. It's a tad slow\n",
    "\n",
    "#for url, fn in zip(df['URL'], df['FILENAME']):                # This will get all objects\n",
    "for url, fn in zip(df['URL'].values[0:20], df['FILENAME'].values[0:20]): # This gets the first 20 objects\n",
    "    u = url.decode('utf-8')\n",
    "    f = '/'.join(fn.decode('utf-8')[1:].split('/')[:-1]) # drop preceding \"/\" and the file name\n",
    "    try:\n",
    "        cmd = 'wget ' + u + '-P ' + f\n",
    "        os.system(cmd)\n",
    "    except:\n",
    "        print('no URL for this galaxy') ## Expect at least 10 exceptions because 10 have 'xxx' for urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAMA includes the spectra of all galaxies in these fields, even if they were originally observed by another survey.\n",
    "We're only looking at the \"best\" spectrum for each galaxy, and sometimes that spectrum came from another survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Looking at some stats\n",
    "\n",
    "gama_c = 0\n",
    "gamaLT_c = 0\n",
    "sdss_c = 0\n",
    "dfgrs2_c = 0\n",
    "qz_c = 0\n",
    "slaq_lrg_c = 0\n",
    "slaq_qso_c = 0\n",
    "dfgs6_c = 0\n",
    "mgc_c = 0\n",
    "vvds_c = 0\n",
    "wigglez_c = 0\n",
    "\n",
    "\n",
    "for i, url in enumerate(df['URL']):\n",
    "    u = url.decode('utf-8')\n",
    "    if '/sdss/' in u:\n",
    "        sdss_c += 1\n",
    "    elif '/gama_LT/' in u:\n",
    "        gamaLT_c += 1\n",
    "    elif '/gama/' in u:\n",
    "        gama_c += 1\n",
    "    elif '/2dfgrs/' in u:\n",
    "        dfgrs2_c += 1\n",
    "    elif '/2qz/' in u:\n",
    "        qz_c += 1\n",
    "    elif '/2slaq-lrg/' in u:\n",
    "        slaq_lrg_c += 1\n",
    "    elif '/2slaq-qso/' in u:\n",
    "        slaq_qso_c += 1\n",
    "    elif '/6dfgs/' in u:\n",
    "        dfgs6_c += 1\n",
    "    elif '/mgc/' in u:\n",
    "        mgc_c += 1\n",
    "    elif '/vvds/' in u:\n",
    "        vvds_c += 1 \n",
    "    elif '/wigglez/' in u:\n",
    "        wigglez_c += 1 \n",
    "    else:\n",
    "        print('URL='+str(u)) #, df.iloc[i])\n",
    "\n",
    "print('\\nsdss: ', sdss_c, '\\nGAMA, LT: ', gama_c, gamaLT_c, '\\n2dfgrs: ', dfgrs2_c, '\\n2QZ: ', qz_c,\n",
    "       '\\nslaq_lrg_c', slaq_lrg_c, '\\nslaq_qso_c: ', slaq_qso_c, '\\ndfgs6_c', dfgs6_c, '\\nmgc_c', mgc_c, \n",
    "      '\\nvvds_c', vvds_c, '\\nwigglez_c', wigglez_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with some spectra!\n",
    "\n",
    "Here are the surveys included in the data lists along with the number of spectra from each survey.\n",
    "\n",
    "1. GAMA : 133494\n",
    "2. SDSS : 23228 \n",
    "3. VVDS (VIMOS VLT Deep Survey) : 66\n",
    "\n",
    "None of these are flux calibrated so we probably can't use them:\n",
    "4. GAMA_LT (GAMA Liverpool Telescope) : 15  \n",
    "5. ^ 2dFGRS (The 2dF Galaxy Redshift Survey) : 2075  \n",
    "6. ^ 2QZ (2dF QSO Redshift Survey) : 157 \n",
    "7. 2SLAQ-LRG (2dF-SDSS LRG and QSO (2SLAQ) Luminous Red Galaxy Survey) : 27 \n",
    "8. 2SLAQ-QSO (2dF-SDSS LRG and QSO (2SLAQ) Luminous Red Galaxy Survey) : 32\n",
    "9. MGC (Millinium Galaxy Catalog) : 664 \n",
    "10. WiggleZ : 87\n",
    "11. 6dFGS (6dF Galaxy Survey) : 171 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAMA\n",
    "\n",
    "These have 1 HDU with 5 rows where:\n",
    "- ROW1    = 'Spectrum'           / Flux-calibrated spectrum in 10^-17 erg/s/cm^2/A\n",
    "- ROW2    = 'Error   '           / 1 sigma error spectrum                         \n",
    "- ROW3    = 'Spectrum_nocalib'   / Spectrum without flux calibration              \n",
    "- ROW4    = 'Error_nocalib'      / 1 sigma error spectrum (no flux calibration)   \n",
    "- ROW5    = 'Sky     '           / Sky spectrum (no flux calibration)   (Sky spectra are removed from the science spectrum during calibration)\n",
    "\n",
    "This information can be found in the headers of the data. \n",
    "\n",
    "The flux is reported in units of 10^-17 erg/s/cm^2/A. \n",
    "\n",
    "The wavelength can be determined also based on header values. \n",
    "It can be described by a simple linear relationship:\n",
    "- 'CD1_1' = slope\n",
    "- 'WMIN' = intercept\n",
    "    \n",
    "    lambda = slope * x + intercept\n",
    "    \n",
    "   where x =  0,..N, where N is the total number of pixels and lambda is in Angstroms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open a file from GAMA \n",
    "# use only the first HDU that contains the spectrum \n",
    "\n",
    "f = df['FILENAME'].values[0].decode('utf-8')[1:].strip()\n",
    "print(f)\n",
    "gama_hdu = fits.open(f)\n",
    "gama_fits = gama_hdu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gama_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gama_fits.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set the wavelengths of the spectra\n",
    "# Make sure these match the WMIN and WMAX from the headers above\n",
    "\n",
    "x_gama = np.arange(0, len(gama_fits.data[0]))\n",
    "wv_gama = gama_fits.header['CD1_1']*x_gama + gama_fits.header['WMIN']\n",
    "\n",
    "print(wv_gama[0], wv_gama[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Quick plot of the spectrum plus the variance. \n",
    "# Turn on the the other plotting functions to see what non-calibrated spectra look like. \n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# plt.plot(wv_gama, gama_fits.data[0], label='Spectrum')\n",
    "# plt.plot(wv_gama, gama_fits.data[1], label=r'$1\\sigma$ Error')\n",
    "plt.plot(wv_gama, gama_fits.data[0], linewidth=0.5, color='k')\n",
    "sigma = gama_fits.data[1]\n",
    "plt.fill_between(wv_gama, gama_fits.data[0] - sigma, gama_fits.data[0] + sigma, alpha=0.5, color='r')\n",
    "#plt.plot(wv_gama, gama_fits.data[2], label='Non-calibrated Spectrum')\n",
    "#plt.plot(wv_gama, gama_fits.data[3], label=r'$1\\sigma$ Error on Non-calibrated Spectrum')\n",
    "#plt.plot(wv_gama, gama_fits.data[4], label='Sky Spectrum') \n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "#plt.ylim(-10, 30)\n",
    "plt.xlim(gama_fits.header['WMIN'], gama_fits.header['WMAX'])\n",
    "\n",
    "plt.title('GAMA Spectrum')\n",
    "plt.xlabel(r'Wavelength [$\\AA$]', size=13)\n",
    "plt.ylabel(r'Flux  [$10^{-17}$ erg/s/$cm^2/\\AA$]', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDSS\n",
    "These files have 3 fits extensions:\n",
    "- Primary with 5 dimensions:\n",
    "    1. ARRAY1  = 'SPECTRUM'           / 10^-17 erg/s/cm^2/A                            \n",
    "    2. ARRAY2  = 'VARIANCE'                                                            \n",
    "    3. ARRAY3  = 'SKY     '           / Subtracted sky spectrum                        \n",
    "    4. ARRAY4  = 'MODEL   '           / Best fit used for classification and redshift  \n",
    "    5. ARRAY5  = 'WDISP   '           / Wavelength dispersion             \n",
    "- MASKS\n",
    "- SPECOBJ\n",
    "- SPZLINE\n",
    "\n",
    "We only need the primary HDU. \n",
    "\n",
    "The flux is in the same units as in GAMA; however the wavelength is given in log10. \n",
    "- 'CDELT1': slope in log10\n",
    "- 'CRVAL1': intercept in log10\n",
    "\n",
    "    lambda = 10^(slope * x + intercept)\n",
    "    \n",
    "where x =  0,..N, where N is the total number of pixels and lambda is in Angstroms.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = df['FILENAME'].values[8].decode('utf-8')[1:].strip() \n",
    "print(f)\n",
    "\n",
    "sdss_hdu = fits.open(f)\n",
    "sdss_fits = sdss_hdu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdss_hdu.info()\n",
    "df.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdss_fits.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_sdss = np.arange(0, len(sdss_fits.data[0]))\n",
    "wv_sdss_log = sdss_fits.header['CRVAL1'] + sdss_fits.header['CDELT1']* x_sdss\n",
    "wv_sdss = 10**(wv_sdss_log)\n",
    "\n",
    "print(wv_sdss[0], wv_sdss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# plt.plot(wv_sdss, sdss_fits.data[0], label='Spectrum')\n",
    "# plt.plot(wv_sdss, sdss_fits.data[1], label='Variance')\n",
    "plt.plot(wv_sdss, sdss_fits.data[0], color='k', linewidth=0.5)\n",
    "sigma = sdss_fits.data[1]\n",
    "plt.fill_between(wv_sdss, sdss_fits.data[0] - sigma, sdss_fits.data[0] + sigma, alpha=0.5, color='r')\n",
    "#plt.plot(wv_sdss, sdss_fits.data[2], label='Sky Spectrum')\n",
    "#plt.plot(wv_sdss, sdss_fits.data[3], label='Best fit model')\n",
    "#plt.plot(wv_sdss, sdss_fits.data[5], label='Wavelenght dispersion')\n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.xlim(sdss_fits.header['WMIN'], sdss_fits.header['WMAX'])\n",
    "\n",
    "plt.title('SDSS Spectrum')\n",
    "plt.xlabel(r'Wavelength [$\\AA$]', size=13)\n",
    "plt.ylabel(r'Flux  [$10^{-17}$ erg/s/$cm^2/\\AA$]', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VVDS\n",
    "There is 1 HDU with 3 elements\n",
    "- ROW1    = 'SPECTRUM'                                                            \n",
    "- ROW2    = 'ERROR   '                                                            \n",
    "- ROW3    = 'SKY     '   \n",
    "\n",
    "These spectra ARE FLUX CALIBRATED, but they are not divided by 10^17 like the other 2. \n",
    "Linear wavelength, Converted the flux to be to be same units as GAMA and SDSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look for a file to download\n",
    "for i, s in enumerate(df['SURVEY']):\n",
    "    survey = s.decode('utf-8')\n",
    "    if 'VVDS' in survey:\n",
    "        print(survey, i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: you can view the object here http://www.gama-survey.org/dr3/tools/sov.php once you get its CATID\n",
    "df.iloc[137087]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = 'wget ' + df.iloc[137087]['URL'].decode('utf-8') + '-P ' \\\n",
    "       + '/'.join(df.iloc[137087]['FILENAME'].decode('utf-8')[1:].split('/')[:-1])\n",
    "\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = df['FILENAME'].values[137087].decode('utf-8')[1:].strip() \n",
    "print(f)\n",
    "\n",
    "vvds_hdu = fits.open(f)\n",
    "vvds_fits = vvds_hdu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vvds_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vvds_fits.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vvds = np.arange(0, len(vvds_fits.data[0]))\n",
    "wv_vvds = vvds_fits.header['CDELT1']*x_vvds + vvds_fits.header['WMIN']\n",
    "\n",
    "print(wv_vvds[0], wv_vvds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# plt.plot(wv_vvds, vvds_fits.data[0]/1e-17, label='Spectrum')\n",
    "# plt.plot(wv_vvds, vvds_fits.data[1]/1e-17, label='Error')\n",
    "sigma = vvds_fits.data[1]/1e-17\n",
    "plt.plot(wv_vvds, vvds_fits.data[0]/1e-17, color='k', linewidth=0.5)\n",
    "plt.fill_between(wv_vvds, vvds_fits.data[0]/1e-17 - sigma, vvds_fits.data[0]/1e-17 + sigma, alpha=0.5, color='r')\n",
    "#plt.plot(wv_sdss, sdss_fits.data[2], label='Sky Spectrum')\n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.xlim(vvds_fits.header['WMIN'], vvds_fits.header['WMAX'])\n",
    "\n",
    "plt.title('VVDS Spectrum')\n",
    "plt.xlabel(r'Wavelength [$\\AA$]', size=13)\n",
    "plt.ylabel(r'Flux  [$10^{-17}$ erg/s/$cm^2/\\AA$]', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2dFGRS \n",
    "\n",
    "These have 1 HDU with 3 rows where:\n",
    "- ROW1    = 'SPECTRUM'                                                            \n",
    "- ROW2    = 'VARIANCE'                                                            \n",
    "- ROW3    = 'SKY     '    \n",
    "\n",
    "Wavelength is the normal linear solution.\n",
    "\n",
    "The spectrum is given in arbitrary flux units. *The 2dFGRS spectra are not flux-calibrated.*\n",
    "\n",
    "Some of these objects have photometry from SDSS though. \n",
    "Because these are not flux calibrated, we cannot use them, but I include it here as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I did not download a 2dFGRS spectrum in the first 20 entries, so I need to find one to download\n",
    "for i, s in enumerate(df['SURVEY']):\n",
    "    survey = s.decode('utf-8')\n",
    "    if '2dFGRS' in survey:\n",
    "        print(survey, i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = 'wget ' + df.iloc[153]['URL'].decode('utf-8') + '-P ' \\\n",
    "       + '/'.join(df.iloc[153]['FILENAME'].decode('utf-8')[1:].split('/')[:-1])\n",
    "\n",
    "    \n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = df['FILENAME'].values[153].decode('utf-8')[1:].strip()\n",
    "print(f)\n",
    "\n",
    "dfgrs2_hdu = fits.open(f)\n",
    "dfgrs2_fits = dfgrs2_hdu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfgrs2_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfgrs2_fits.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dfgrs2 = np.arange(0, len(dfgrs2_fits.data[0]))\n",
    "wv_dfgrs2 = dfgrs2_fits.header['CDELT1']*x_dfgrs2 + dfgrs2_fits.header['WMIN']\n",
    "\n",
    "print(wv_dfgrs2[0], wv_dfgrs2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.plot(wv_dfgrs2, dfgrs2_fits.data[0], label='Spectrum')\n",
    "#plt.plot(wv_dfgrs2, dfgrs2_fits.data[1], label='Variance')\n",
    "#plt.plot(wv_dfgrs2, dfgrs2_fits.data[2], label='Sky Spectrum')\n",
    "\n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(dfgrs2_fits.header['WMIN'], dfgrs2_fits.header['WMAX'])\n",
    "plt.ylim(-20, 400)\n",
    "\n",
    "plt.title('2dFGRS Spectrum')\n",
    "plt.xlabel(r'Wavelength [$\\AA$]', size=13)\n",
    "plt.ylabel('Flux [Arbitrary Units]', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2QZ\n",
    "\n",
    "Three HDUs\n",
    "- Primary (spectrum)\n",
    "- Bad pixel masks\n",
    "- Variance \n",
    "\n",
    "Normal linear wavelenght solution.\n",
    "\n",
    "Spectra are not given in flux units and so can be converted via BZERO and BSCALE headers\n",
    "    True_value = BSCALE * FITS_value + BZERO \n",
    "   \n",
    "Because these are not flux calibrated, we cannot use them, but I include it here as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, s in enumerate(df['SURVEY']):\n",
    "    survey = s.decode('utf-8')\n",
    "    if '2QZ' in survey:\n",
    "        print(survey, i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[16825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = 'wget ' + df.iloc[16825]['URL'].decode('utf-8') + '-P ' \\\n",
    "       + '/'.join(df.iloc[16825]['FILENAME'].decode('utf-8')[1:].split('/')[:-1])\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open these the same as the others.\n",
    "# However, the variance is split into a different HDU instead of being another array in the Primary HDU\n",
    "\n",
    "f = df['FILENAME'].values[16825].decode('utf-8')[1:].strip()\n",
    "print(f)\n",
    "\n",
    "qz_hdu = fits.open(f)\n",
    "qz_fits = qz_hdu[0]\n",
    "qz_var = qz_hdu[2]   ## variance HDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qz_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qz_fits.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qz_var.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_qz = np.arange(0, len(qz_fits.data))\n",
    "wv_qz = qz_fits.header['CD1_1']*x_qz + qz_fits.header['WMIN']\n",
    "\n",
    "print(wv_qz[0], wv_qz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### On GAMAs single object viewer, they do not do this conversion\n",
    "\n",
    "## convert data to physical units\n",
    "## the headers are sometimes not there??\n",
    "#qz_data_array = qz_fits.header['BSCALE'] * qz_fits.data + qz_fits.header['BZERO']\n",
    "#qz_var_array = qz_var.header['BSCALE'] * qz_var.data + qz_var.header['BZERO']\n",
    "\n",
    "#spec_slope = qz_fits.header['BSCALE']\n",
    "#spec_inter = qz_fits.header['BZERO']\n",
    "#var_slope = qz_var.header['BSCALE']\n",
    "#var_inter = qz_var.header['BZERO']\n",
    "\n",
    "#qz_data_array = spec_slope * qz_fits.data + spec_inter\n",
    "#qz_var_array = var_slope * qz_var.data +var_inter\n",
    "\n",
    "# For some reason this strips the BZERO and BSCALE keywords from the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.plot(wv_qz, qz_fits.data, label='Spectrum')\n",
    "#plt.plot(wv_qz, qz_var.data, label='Variance')\n",
    "\n",
    "#plt.axhline(0, color='k')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(qz_fits.header['WMIN'], qz_fits.header['WMAX'])\n",
    "#plt.ylim(-20, 400)\n",
    "\n",
    "plt.title('2QZ Spectrum')\n",
    "plt.xlabel(r'Wavelength [$\\AA$]', size=13)\n",
    "plt.ylabel('Flux [Arbitrary Units]', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting photometry from spectra\n",
    "\n",
    "The goal of this project is to make realistic mock galaxy catalogs of photometry, not spectra.\n",
    "Photometry refers to an extremely coarse spectrum whose pixels are the flux through a handful of broadband filters.\n",
    "We're starting from spectra rather than another photometric dataset because we would in general want to make a mock catalog for a survey with different filters than the available real galaxy catalog.\n",
    "However, we don't want to work with spectra because they're high dimensional, and we're going to downsample them to photometry for the final catalog anyway.\n",
    "Therefore, we can turn our input spectra into photometry with the same filters as the target mock catalog.\n",
    "\n",
    "*Caveat: This assumes that the photometric observations would have the same systematics of the optics, etc.\n",
    "We'll have to discuss this in the paper. . .*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter transmission curves for LSST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is adapted from https://github.com/sncosmo/sncosmo/blob/master/docs/_helpers/bandpass_page.py\n",
    "\n",
    "def plot_bandpass_set(setname):\n",
    "    \"\"\"Plot the given set of bandpasses.\"\"\"\n",
    "\n",
    "    bandpass_meta = sncosmo.bandpasses._BANDPASSES.get_loaders_metadata()\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    ax = plt.axes()\n",
    "\n",
    "    nbands = 0\n",
    "    for m in bandpass_meta:\n",
    "        if m['filterset'] != setname:\n",
    "            continue\n",
    "        b = sncosmo.get_bandpass(m['name'])\n",
    "\n",
    "        # add zeros on either side of bandpass transmission\n",
    "        wave = np.zeros(len(b.wave) + 2)\n",
    "        wave[0] = b.wave[0]\n",
    "        wave[1:-1] = b.wave\n",
    "        wave[-1] = b.wave[-1]\n",
    "        trans = np.zeros(len(b.trans) + 2)\n",
    "        trans[1:-1] = b.trans\n",
    "\n",
    "        ax.plot(wave, trans, label=m['name'])\n",
    "        nbands += 1\n",
    "\n",
    "    ax.set_xlabel(\"Wavelength ($\\\\AA$)\", size=12)\n",
    "    ax.set_ylabel(\"Transmission\", size=12)\n",
    "\n",
    "    ncol = 1 + (nbands-1) // 9  # 9 labels per column\n",
    "    ax.legend(loc='upper right', frameon=False, fontsize='x-large',\n",
    "              ncol=ncol)\n",
    "\n",
    "    # Looks like each legend column takes up about 0.125 of the figure.\n",
    "    # Make room for the legend.\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    xmax += ncol * 0.125 * (xmax - xmin)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_bandpass_set('lsst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to calculate photometry from spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is mostly an SNCOSMO code that KAP updated to be able to return spectra\n",
    "from sncosmo_spectrum import Spectrum as sncosmo_Spec \n",
    "\n",
    "def photometry(wavelength, spectrum, variance, band, magnitudes=True, magsystem='ab', **kwargs):\n",
    "    '''\n",
    "        band: Check sncosmo for list of bands\n",
    "        magsystem: Check sncosmo for list of magsystems\n",
    "        \n",
    "        bandpasses build into SNCosmo: \n",
    "        Bessel, SNLS, DES, SDSS, HST ACS WFC, WFC3 IR,\n",
    "        WFC2 UVIS, Kepler, CSP, JWST NIRCAM/MIRI (nah), \n",
    "        LSST, keplercam, 4shooter\n",
    "    '''\n",
    "    # Define a spectrum object\n",
    "    #spectrum = sncosmo.Spectrum(wavelength, spectrum)\n",
    "    spectrum = sncosmo_Spec(wavelength, spectrum, error=variance)\n",
    "\n",
    "    # Calculate flux and flux error in specific band\n",
    "    flux, fluxerr = spectrum.bandflux(band)\n",
    "\n",
    "    # MagSystem\n",
    "    mag = sncosmo.get_magsystem(magsystem)\n",
    "    \n",
    "    # Calculate magnitudes and mag errors from flux\n",
    "    magn = mag.band_flux_to_mag(flux, band)\n",
    "    magerr = 2.5/np.log(10) / flux * fluxerr \n",
    "    #2.5/np.log(10) / bsnf2[0] * bsnf2[1]\n",
    "\n",
    "    if magnitudes:\n",
    "        return magn, magerr\n",
    "    else:\n",
    "        return flux , fluxerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell creates an array of zeros of size (N spectra, M bandpasses).\n",
    "# Here we can set some limits if we want so that we don't open everything, but we can choose to do this later\n",
    "# right now it opens everything but I included the df keywords for probability the redshift is right ('PROB') and \n",
    "# the 'NQ' which should be larger than 2 based off the GAMA header\n",
    "# once everything is read in, I clean the data of NANs and then generate the photometry.\n",
    "\n",
    "header_keyword_dict = {'GAMA': 'CD1_1', 'SDSS': 'CDELT1', 'VVDS': 'CDELT1'}\n",
    "bandpasses = ['lsstg', 'lsstr', 'lssti']\n",
    "\n",
    "phot_measures = np.zeros((len(df[0:20]), len(bandpasses), 2))\n",
    "\n",
    "for n, expand in enumerate(df[0:20].iterrows()):\n",
    "    index, row = expand\n",
    "    if row['PROB'] > -0.68 and row['NQ'] > 2:\n",
    "        s = row['SURVEY'].decode('utf-8').strip()\n",
    "        if s in ['GAMA', 'SDSS', 'VVDS']:\n",
    "            \n",
    "            f = row['FILENAME'].decode('utf-8')[1:].strip()\n",
    "            hdu = fits.open(f)\n",
    "            spectrum = hdu[0].data[0]\n",
    "            error = hdu[0].data[1]\n",
    "            header_info = hdu[0].header\n",
    "            \n",
    "            x = np.arange(0, len(spectrum))\n",
    "            if s in 'SDSS':\n",
    "                wv_log = header_info['CRVAL1'] + header_info[header_keyword_dict[s]] * x\n",
    "                wv = 10**(wv_log)\n",
    "            else:\n",
    "                wv = header_info['WMIN'] + header_info[header_keyword_dict[s]] * x\n",
    "                        \n",
    "            if s in 'VVDS':\n",
    "                spectrum = spectrum/1e-17\n",
    "                error = error/1e-17\n",
    "\n",
    "            # Now I need to clean out the nans from the flux.\n",
    "            nonan_flux = np.array([x for x in spectrum if not np.isnan(x)])\n",
    "            \n",
    "            nonan_wv = []\n",
    "            nonan_err = []\n",
    "            for w, f, e in zip(wv, spectrum, error):\n",
    "                if ~np.isnan(f):\n",
    "                    nonan_wv.append(w)\n",
    "                    nonan_err.append(e)\n",
    "            nonan_wv = np.array(nonan_wv)\n",
    "            nonan_err = np.array(nonan_err)\n",
    "\n",
    "            for i, b in enumerate(bandpasses):\n",
    "                try:\n",
    "                    mag, mag_err = photometry(nonan_wv, nonan_flux*1e-17, nonan_err*1e-17, b)\n",
    "                    phot_measures[n, i, 0] = mag\n",
    "                    phot_measures[n, i, 1] = mag_err\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            hdu.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You'll see here a bad pixel in spectrum for iloc=17 causing the g-band to fail to produce photometry\n",
    "phot_measures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open(df.iloc[17]['FILENAME'].decode('utf-8')[1:].strip())\n",
    "spectrum = hdu[0].data[0]\n",
    "header_info = hdu[0].header\n",
    "x = np.arange(0, len(spectrum))\n",
    "wv = header_info['WMIN'] + header_info['CD1_1'] * x\n",
    "plt.plot(wv, spectrum)\n",
    "# plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## In order to add these to the data frame, \n",
    "#I do a deep copy of only the files I downloaded and then added the columns. \n",
    "df20 = df.copy()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "band_err = ['lsstg_err', 'lsstr_err', 'lssti_err']\n",
    "for i, b in enumerate(zip(bandpasses, band_err)):\n",
    "    bp, bp_err = b\n",
    "    df20[bp] = phot_measures[:, i, 0]\n",
    "    df20[bp_err] = phot_measures[:, i, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between redshift and photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(df20['Z'], df20['lsstg'], 'o', alpha=0.5, label='LSSTr')\n",
    "# plt.plot(df20['Z'], df20['lsstr'], 'o', alpha=0.5, label='LSSTr')\n",
    "# plt.plot(df20['Z'], df20['lssti'], 'o', alpha=0.5, label='LSSTi')\n",
    "\n",
    "# plt.ylim(12, 22)\n",
    "# plt.legend()\n",
    "# plt.xlabel('redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mycorner(datum, keys, color_by, lims=None):#, filename='plot.pdf'):\n",
    "    ncol = len(keys)\n",
    "    fig = plt.figure(figsize=(ncol*5, ncol*5))\n",
    "    ax = [[fig.add_subplot(ncol, ncol, ncol * i + j + 1) for j in range(i+1)] for i in range(ncol)]\n",
    "    for i in range(ncol):\n",
    "        for j in range(i+1):\n",
    "            if i == j:\n",
    "                ax[i][j].hist(datum[keys[i]], bins=50, histtype='step', linewidth=2, density=True, alpha=0.75, color='k')\n",
    "                ax[i][j].set_xlabel(keys[i])\n",
    "                ax[i][j].set_xlim(lims[keys[i]])\n",
    "            else:\n",
    "                ax[i][j].scatter(datum[keys[i]], datum[keys[j]], c=datum[color_by])\n",
    "                ax[i][j].set_xlabel(keys[i])\n",
    "                ax[i][j].set_ylabel(keys[j])\n",
    "                if lims is not None:\n",
    "                    ax[i][j].set_xlim(lims[keys[i]])\n",
    "                    ax[i][j].set_ylim(lims[keys[j]])\n",
    "#     fig.savefig(filename, dpi=100)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = {'lsstg': (17., 22.), 'lsstr': (17., 20.), 'lssti': (17., 20.)}\n",
    "\n",
    "mycorner(df20, bandpasses, 'Z', lims=lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color plot\n",
    "\n",
    "# plt.plot(df20['Z'], df20['lsstg']- df20['lsstr'], 'o', alpha=0.5, label='g-r')\n",
    "# plt.plot(df20['Z'], df20['lsstr']- df20['lssti'], 'o', alpha=0.5, label='r-i')\n",
    "# plt.ylim(-1., 2)\n",
    "fig, ax = plt.subplots()\n",
    "cax = plt.scatter(df20['lsstg']- df20['lsstr'], df20['lsstr']- df20['lssti'], c=df20['Z']/max(df20['Z']))\n",
    "plt.xlim(0., 1.5)\n",
    "plt.ylim(0., 1.)\n",
    "cbar = fig.colorbar(cax, ticks=z_bins/max(df20['Z']))\n",
    "cbar.ax.set_yticklabels(z_bins)\n",
    "cbar.set_label('redshift', rotation=270)\n",
    "# plt.legend()\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('r-i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over a larger redshift range, this latter plot usually looks much more convincing of a correlation than the one with magnitudes. . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "\n",
    "## choose and implement a measure of \"environment\"\n",
    "\n",
    "## construct redshift-environment-SED/color relationship\n",
    "\n",
    "## TBD Question: Is the flux given the restframe? Most likely but I should double check just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
